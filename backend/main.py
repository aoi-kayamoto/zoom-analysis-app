import os
import gc
import re
import math
import tempfile
import subprocess
from pathlib import Path

from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse

app = FastAPI(title="Coach Dashboard API")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
async def root():
    return FileResponse("../frontend/index.html")

def extract_audio(video_path: str, out_path: str):
    cmd = ["ffmpeg", "-y", "-i", video_path, "-ar", "16000", "-ac", "1", "-f", "wav", out_path]
    result = subprocess.run(cmd, capture_output=True, text=True)
    if result.returncode != 0:
        raise RuntimeError(f"ffmpeg ã‚¨ãƒ©ãƒ¼: {result.stderr}")

def transcribe_audio(audio_path: str) -> list[dict]:
    from faster_whisper import WhisperModel
    model = None
    try:
        model = WhisperModel("small", device="cpu", compute_type="int8")
        segments, info = model.transcribe(
            audio_path, language="ja", vad_filter=True,
            vad_parameters={"min_silence_duration_ms": 500}, beam_size=5,
        )
        return [{"start": round(s.start,2), "end": round(s.end,2), "text": s.text.strip(), "duration": round(s.end-s.start,2)} for s in segments]
    finally:
        del model
        gc.collect()

COACH_PATTERNS = re.compile(r'(ã©ã†|ã§ã™ã‹|ã¾ã—ãŸã‹|ã¾ã™ã‹|ã¾ã—ã‚‡ã†|ã„ã‹ãŒã§ã™ã‹|æ•™ãˆã¦ãã ã•ã„|ãªã‚‹ã»ã©|ãã†ã§ã™ã­|ãŠã£ã—ã‚ƒã‚‹|ã‚ã‚ŠãŒã¨ã†|ã¾ãš|ç¢ºèª|æ•´ç†|ã©ã‚“ãª|ã©ã®ã‚ˆã†|ä½•ãŒ|èª°ãŒ|ã„ã¤|ã©ã“ã§|ãªãœ|ã©ã‚Œ)', re.IGNORECASE)

def assign_speakers(segments: list[dict]) -> list[dict]:
    labeled = []
    prev_speaker = "coach"
    for i, seg in enumerate(segments):
        text = seg["text"]
        coach_score = 0
        if COACH_PATTERNS.search(text): coach_score += 1
        if text.endswith("ã‹") or text.endswith("ã‹ï¼Ÿ") or text.endswith("?"): coach_score += 1
        if seg["duration"] > 40: coach_score -= 1
        if i == 0: speaker = "coach"
        elif prev_speaker == "coach": speaker = "coach" if coach_score >= 2 else "student"
        else: speaker = "coach" if coach_score >= 1 else "student"
        prev_speaker = speaker
        labeled.append({**seg, "speaker": speaker})
    return labeled

def calc_statistics(segments: list[dict]) -> dict:
    coach_segs   = [s for s in segments if s["speaker"] == "coach"]
    student_segs = [s for s in segments if s["speaker"] == "student"]
    coach_time   = sum(s["duration"] for s in coach_segs)
    student_time = sum(s["duration"] for s in student_segs)
    total_time   = coach_time + student_time or 1
    coach_pct    = round(coach_time / total_time * 100, 1)
    longest      = max((s["duration"] for s in segments), default=0)
    silences     = [round(segments[i]["start"] - segments[i-1]["end"], 1) for i in range(1, len(segments)) if segments[i]["start"] - segments[i-1]["end"] >= 3]
    avg_coach    = (coach_time / len(coach_segs)) if coach_segs else 0
    questions    = [s for s in coach_segs if re.search(r'[?ï¼Ÿ]|ã‹[ã€‚ã€€\s]?$', s["text"])]
    open_q       = len([q for q in questions if COACH_PATTERNS.search(q["text"])])
    return {
        "coach_pct": coach_pct, "student_pct": round(100 - coach_pct, 1),
        "coach_turns": len(coach_segs), "student_turns": len(student_segs),
        "longest_speech": round(longest, 1),
        "longest_speech_alert": "danger" if longest >= 60 else "warning" if longest >= 30 else "safe",
        "silence_count": len(silences), "silence_avg": round(sum(silences)/len(silences),1) if silences else 0,
        "avg_coach_duration": round(avg_coach, 1),
        "question_count": len(questions), "open_questions": open_q, "closed_questions": len(questions) - open_q,
    }

EMPATHY_WORDS  = re.compile(r'(ãªã‚‹ã»ã©|ãã†ã§ã™ã­|ã‚ã‹ã‚Šã¾ã™|å¤§å¤‰ã§ã—ãŸã­|ã¤ã‚‰ã„|æ„Ÿã˜|æ°—æŒã¡)')
APPROVAL_WORDS = re.compile(r'(ã„ã„ã§ã™ã­|ç´ æ™´ã‚‰ã—ã„|ã‚ˆã‹ã£ãŸ|ã§ãã¦ã„ã¾ã™|ã™ã”ã„|ã•ã™ãŒ|ã‚ã‚ŠãŒã¨ã†)')

def calc_skill_scores(segments: list[dict], stats: dict) -> dict:
    coach_texts = " ".join(s["text"] for s in segments if s["speaker"] == "coach")
    empathy_score  = min(5, max(1, round(len(EMPATHY_WORDS.findall(coach_texts)) / 2)))
    approval_score = min(5, max(1, round(len(APPROVAL_WORDS.findall(coach_texts)) / 1.5)))
    open_ratio     = stats["open_questions"] / (stats["question_count"] or 1)
    question_score = min(5, max(1, round(open_ratio * 5)))
    silence_score  = min(5, max(1, math.ceil(stats["silence_count"] / 2)))
    listening_score= min(5, max(1, round(stats["student_pct"] / 20)))
    return {"empathy": empathy_score, "approval": approval_score, "question": question_score, "silence": silence_score, "listening": listening_score}

def generate_advice(stats: dict, scores: dict) -> list[dict]:
    advice = []
    if stats["longest_speech"] >= 60:
        advice.append({"level":"red","text":f"æœ€é•·ç™ºè©±ãŒ{stats['longest_speech']}ç§’ï¼ˆğŸš¨ è©±ã—ã™ãï¼‰ï¼š30ç§’ã‚’ç›®å®‰ã«ã€Œã©ã†æ€ã„ã¾ã™ã‹ï¼Ÿã€ã¨å•ã„ã‚’è¿”ã—ã¾ã—ã‚‡ã†ã€‚"})
    elif stats["longest_speech"] >= 30:
        advice.append({"level":"amber","text":f"æœ€é•·ç™ºè©±ãŒ{stats['longest_speech']}ç§’ï¼ˆâš  è¦æ³¨æ„ï¼‰ï¼šå—è¬›ç”ŸãŒè€ƒãˆã‚‹ä½™ç™½ã‚’æ„è­˜ã—ã¦ãã ã•ã„ã€‚"})
    if stats["coach_pct"] > 50:
        advice.append({"level":"amber","text":f"ã‚³ãƒ¼ãƒç™ºè©±ç‡ãŒ{stats['coach_pct']}%ï¼šç†æƒ³ã¯å—è¬›ç”ŸãŒ60ã€œ70%è©±ã™çŠ¶æ…‹ã§ã™ã€‚ã€Œã‚‚ã†å°‘ã—æ•™ãˆã¦ãã ã•ã„ã€ã‚’æ„è­˜çš„ã«å¢—ã‚„ã—ã¾ã—ã‚‡ã†ã€‚"})
    else:
        advice.append({"level":"green","text":f"ç™ºè©±ãƒãƒ©ãƒ³ã‚¹ãŒè‰¯å¥½ï¼ˆå—è¬›ç”Ÿ{stats['student_pct']}%ï¼‰ï¼šå—è¬›ç”ŸãŒååˆ†ã«è©±ã›ã‚‹ç’°å¢ƒã‚’ä½œã‚Œã¦ã„ã¾ã™ã€‚"})
    if scores["question"] <= 2:
        advice.append({"level":"amber","text":f"å•ã„ã‚¹ã‚³ã‚¢ãŒä½ã‚ï¼ˆâ˜…{scores['question']}ï¼‰ï¼šã€Œã©ã‚“ãªæ°—æŒã¡ã§ã—ãŸã‹ï¼Ÿã€ãªã©ã‚ªãƒ¼ãƒ—ãƒ³è³ªå•ã‚’å¢—ã‚„ã—ã¾ã—ã‚‡ã†ã€‚"})
    if scores["approval"] >= 4:
        advice.append({"level":"green","text":f"æ‰¿èªã‚¹ã‚³ã‚¢ãŒè‰¯å¥½ï¼ˆâ˜…{scores['approval']}ï¼‰ï¼šå—è¬›ç”Ÿã®ç™ºè¨€ã‚’å—ã‘æ­¢ã‚ã€æ‰¿èªã™ã‚‹è¨€è‘‰ãŒå¤šãè¦‹ã‚‰ã‚Œã¾ã—ãŸã€‚"})
    if stats["silence_count"] == 0:
        advice.append({"level":"amber","text":"æ²ˆé»™ãŒã»ã¨ã‚“ã©ã‚ã‚Šã¾ã›ã‚“ï¼šæ„å›³çš„ã«2ã€œ3ç§’å¾…ã¤ã“ã¨ã§ã€å—è¬›ç”ŸãŒæ·±ãè€ƒãˆã‚‹æ™‚é–“ã‚’ä½œã‚Œã¾ã™ã€‚"})
    return advice

@app.post("/analyze")
async def analyze(file: UploadFile = File(...)):
    allowed = {".mp4", ".mov", ".m4a", ".mp3", ".wav", ".webm"}
    suffix = Path(file.filename).suffix.lower()
    if suffix not in allowed:
        raise HTTPException(400, f"æœªå¯¾å¿œã®å½¢å¼: {suffix}")
    with tempfile.TemporaryDirectory() as tmpdir:
        input_path = os.path.join(tmpdir, f"input{suffix}")
        with open(input_path, "wb") as f:
            f.write(await file.read())
        if suffix in {".mp4", ".mov", ".webm"}:
            audio_path = os.path.join(tmpdir, "audio.wav")
            extract_audio(input_path, audio_path)
        else:
            audio_path = input_path
        segments = transcribe_audio(audio_path)
        if not segments:
            raise HTTPException(422, "éŸ³å£°ã‚’æ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
        segments = assign_speakers(segments)
        stats  = calc_statistics(segments)
        scores = calc_skill_scores(segments, stats)
        advice = generate_advice(stats, scores)
        total_sec = segments[-1]["end"] if segments else 0
    return {
        "filename": file.filename,
        "duration": f"{int(total_sec//60)}åˆ†{int(total_sec%60):02d}ç§’",
        "stats": stats, "scores": scores, "advice": advice,
        "segments": segments[:60],
    }

@app.get("/health")
async def health():
    return {"status": "ok"}
